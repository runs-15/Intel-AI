{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incoming-tourist",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(train_X, train_Y), (test_X, test_Y) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "future-helmet",
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1534d38a48e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "n = 9\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(n):\n",
    "    plt.plot(300+1+i)\n",
    "    plt.imshow(train_X[i])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "advanced-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unlike-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train_X.astype('float32')\n",
    "test_X=test_X.astype('float32')\n",
    " \n",
    "train_X=train_X/255.0\n",
    "test_X=test_X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "injured-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y=np_utils.to_categorical(train_Y)\n",
    "test_Y=np_utils.to_categorical(test_Y)\n",
    " \n",
    "num_classes=test_Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "built-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),input_shape=(32,32,3),\n",
    "    padding='same',activation='relu',\n",
    "    kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32,(3,3),activation='relu',padding='same',kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu',kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "great-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd=SGD(learning_rate=0.01,momentum=0.9,decay=(0.01/25),nesterov=False)\n",
    " \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "  optimizer=sgd,\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "professional-measurement",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 32, 32, 32)        896       \n_________________________________________________________________\ndropout (Dropout)            (None, 32, 32, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 8192)              0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               4194816   \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                5130      \n=================================================================\nTotal params: 4,210,090\nTrainable params: 4,210,090\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "express-oklahoma",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Dense.call of <keras.layers.core.Dense object at 0x000002080C9B6B80>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpawy03m_1.py, line 48)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Dense.call of <keras.layers.core.Dense object at 0x000002080C9B6B80>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmpawy03m_1.py, line 48)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1563/1563 [==============================] - 222s 132ms/step - loss: 1.9204 - accuracy: 0.2983 - val_loss: 1.4326 - val_accuracy: 0.4768\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2080d73cc10>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "model.fit(train_X,train_Y,\n",
    "    validation_data=(test_X,test_Y),\n",
    "    epochs=1,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "coated-insertion",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 6s 18ms/step - loss: 1.4326 - accuracy: 0.4768\n",
      "47.679999470710754\n"
     ]
    }
   ],
   "source": [
    "_,acc=model.evaluate(test_X,test_Y)\n",
    "print(acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "applicable-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model1_cifar_1epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "featured-mambo",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Personal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "0 aeroplane\n"
     ]
    }
   ],
   "source": [
    "results={\n",
    "   0:'aeroplane',\n",
    "   1:'automobile',\n",
    "   2:'bird',\n",
    "   3:'cat',\n",
    "   4:'deer',\n",
    "   5:'dog',\n",
    "   6:'frog',\n",
    "   7:'horse',\n",
    "   8:'ship',\n",
    "   9:'truck'\n",
    "}\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "im=Image.open(\"horse.jpg\")\n",
    "# the input image is required to be in the shape of dataset, i.e (32,32,3)\n",
    " \n",
    "im=im.resize((32,32))\n",
    "im=np.expand_dims(im,axis=0)\n",
    "im=np.array(im)\n",
    "pred=model.predict_classes([im])[0]\n",
    "print(pred,results[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "municipal-covering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.6191 - accuracy: 0.7814 - val_loss: 0.9449 - val_accuracy: 0.6798\n",
      "Epoch 2/25\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.5827 - accuracy: 0.7926 - val_loss: 0.9404 - val_accuracy: 0.6829\n",
      "Epoch 3/25\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.5378 - accuracy: 0.8087 - val_loss: 0.9562 - val_accuracy: 0.6860\n",
      "Epoch 4/25\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.5053 - accuracy: 0.8211 - val_loss: 0.9687 - val_accuracy: 0.6827\n",
      "Epoch 5/25\n",
      "1563/1563 [==============================] - 143s 91ms/step - loss: 0.4757 - accuracy: 0.8322 - val_loss: 0.9715 - val_accuracy: 0.6903\n",
      "Epoch 6/25\n",
      "1563/1563 [==============================] - 143s 92ms/step - loss: 0.4422 - accuracy: 0.8438 - val_loss: 0.9876 - val_accuracy: 0.6898\n",
      "Epoch 7/25\n",
      "1563/1563 [==============================] - 143s 92ms/step - loss: 0.4206 - accuracy: 0.8510 - val_loss: 0.9837 - val_accuracy: 0.6940\n",
      "Epoch 8/25\n",
      "1563/1563 [==============================] - 143s 92ms/step - loss: 0.3932 - accuracy: 0.8622 - val_loss: 1.0068 - val_accuracy: 0.6898\n",
      "Epoch 9/25\n",
      "1563/1563 [==============================] - 143s 92ms/step - loss: 0.3722 - accuracy: 0.8696 - val_loss: 1.0032 - val_accuracy: 0.6925\n",
      "Epoch 10/25\n",
      "1563/1563 [==============================] - 143s 91ms/step - loss: 0.3496 - accuracy: 0.8767 - val_loss: 1.0378 - val_accuracy: 0.6933\n",
      "Epoch 11/25\n",
      "1563/1563 [==============================] - 143s 92ms/step - loss: 0.3332 - accuracy: 0.8831 - val_loss: 1.0483 - val_accuracy: 0.6919\n",
      "Epoch 12/25\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.3106 - accuracy: 0.8911 - val_loss: 1.0426 - val_accuracy: 0.6981\n",
      "Epoch 13/25\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.3009 - accuracy: 0.8956 - val_loss: 1.0590 - val_accuracy: 0.6963\n",
      "Epoch 14/25\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.2840 - accuracy: 0.9007 - val_loss: 1.0710 - val_accuracy: 0.6934\n",
      "Epoch 15/25\n",
      "1563/1563 [==============================] - 145s 93ms/step - loss: 0.2732 - accuracy: 0.9049 - val_loss: 1.0688 - val_accuracy: 0.6984\n",
      "Epoch 16/25\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.2587 - accuracy: 0.9107 - val_loss: 1.0821 - val_accuracy: 0.6958\n",
      "Epoch 17/25\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.2502 - accuracy: 0.9135 - val_loss: 1.1062 - val_accuracy: 0.6976\n",
      "Epoch 18/25\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.2409 - accuracy: 0.9162 - val_loss: 1.1005 - val_accuracy: 0.6990\n",
      "Epoch 19/25\n",
      "1563/1563 [==============================] - 145s 93ms/step - loss: 0.2296 - accuracy: 0.9211 - val_loss: 1.1104 - val_accuracy: 0.6993\n",
      "Epoch 20/25\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.2246 - accuracy: 0.9228 - val_loss: 1.1064 - val_accuracy: 0.7003\n",
      "Epoch 21/25\n",
      "1563/1563 [==============================] - 145s 92ms/step - loss: 0.2199 - accuracy: 0.9258 - val_loss: 1.1186 - val_accuracy: 0.6982\n",
      "Epoch 22/25\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.2032 - accuracy: 0.9303 - val_loss: 1.1333 - val_accuracy: 0.6981\n",
      "Epoch 23/25\n",
      "1563/1563 [==============================] - 143s 92ms/step - loss: 0.1989 - accuracy: 0.9311 - val_loss: 1.1276 - val_accuracy: 0.7007\n",
      "Epoch 24/25\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.1909 - accuracy: 0.9347 - val_loss: 1.1498 - val_accuracy: 0.6979\n",
      "Epoch 25/25\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.1877 - accuracy: 0.9343 - val_loss: 1.1537 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19e90fd2a30>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X,train_Y,\n",
    "    validation_data=(test_X,test_Y),\n",
    "    epochs=1,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "distinct-donna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 1.1537 - accuracy: 0.7000\n",
      "69.9999988079071\n"
     ]
    }
   ],
   "source": [
    "_,acc=model.evaluate(test_X,test_Y)\n",
    "print(acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aboriginal-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model1_cifar_25epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "roman-former",
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4d4fda9eb74e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "results={\n",
    "   0:'aeroplane',\n",
    "   1:'automobile',\n",
    "   2:'bird',\n",
    "   3:'cat',\n",
    "   4:'deer',\n",
    "   5:'dog',\n",
    "   6:'frog',\n",
    "   7:'horse',\n",
    "   8:'ship',\n",
    "   9:'truck'\n",
    "}\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "im=Image.open(\"horse.jpg\")\n",
    "# the input image is required to be in the shape of dataset, i.e (32,32,3)\n",
    " \n",
    "im=im.resize((32,32))\n",
    "im=np.expand_dims(im,axis=0)\n",
    "im=np.array(im)\n",
    "pred=model.predict_classes([im])[0]\n",
    "print(pred,results[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-style",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python391jvsc74a57bd064c186e311c60a1caaf695f555b4bd88d018468f9e8b6a4180150a8eb44f5e19",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "64c186e311c60a1caaf695f555b4bd88d018468f9e8b6a4180150a8eb44f5e19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}